{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "#load the dataset\n",
    "df=pd.read_table('SMSspamCollection',header=None,encoding='utf-8')\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check class distribution\n",
    "classes=df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "5    spam\n",
      "6     ham\n",
      "7     ham\n",
      "8    spam\n",
      "9    spam\n",
      "Name: 0, dtype: object\n",
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing of data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(classes)\n",
    "print(classes[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#store the smsmessage data\n",
    "text_message=df[1]\n",
    "print(text_message[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point crazy available only in ...\n",
      "1                       ok lar joking wif u oni moneysymb\n",
      "2       free entry in nmbr a wkly comp to win fa cup f...\n",
      "3       u dun say so early hor u c already then say mo...\n",
      "4       nah i don t think he goes to usf he lives arou...\n",
      "                              ...                        \n",
      "5567    this is the nmbrnd time we have tried nmbr con...\n",
      "5568        will ü b going to esplanade fr home moneysymb\n",
      "5569    pity was in mood for that so any other suggest...\n",
      "5570    the guy did some bitching but i acted like i d...\n",
      "5571                   rofl its true to its namemoneysymb\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#use regular expression to replace email,phoneumber,specialharacter\n",
    "\n",
    "#replace email address with emailaddr\n",
    "processed=text_message.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,} $','emailaddr')\n",
    "\n",
    "#replace urls with webaddr\n",
    "processed=processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\$*)?$','webaddress')\n",
    "\n",
    "#replace money with moneysymbol\n",
    "processed=processed.str.replace(r'$|\\ $','moneysymb')\n",
    "\n",
    "#replace 10 digit phonumber with phonenumber\n",
    "processed=processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4} $','phonenum')\n",
    "\n",
    "#replace normal n numbers with nmbr\n",
    "processed=processed.str.replace(r'\\d+(\\.\\d+)?','nmbr')\n",
    "#replae punctuation\n",
    "processed=processed.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "#remove ws\n",
    "processed=processed.str.replace(r'\\s+',' ')\n",
    "#remove leading and trailing ws\n",
    "processed=processed.str.replace(r'^\\s+|\\s+?$','')\n",
    "\n",
    "processed=processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "processed=processed.apply(lambda x:' '.join(term for term in x.split() if term not in stop_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ing s or es\n",
    "ps=nltk.PorterStemmer()\n",
    "processed=processed.apply(lambda x:' '.join (ps.stem(term)for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     go jurong point crazi avail bugi n great world...\n",
      "1                       ok lar joke wif u oni moneysymb\n",
      "2     free entri nmbr wkli comp win fa cup final tkt...\n",
      "3         u dun say earli hor u c alreadi say moneysymb\n",
      "4         nah think goe usf live around thoughmoneysymb\n",
      "5     freemsg hey darl nmbr week word back like fun ...\n",
      "6     even brother like speak treat like aid patent ...\n",
      "7     per request mell mell oru minnaminungint nurun...\n",
      "8     winner valu network custom select receivea nmb...\n",
      "9     mobil nmbr month u r entitl updat latest colou...\n",
      "10    gonna home soon want talk stuff anymor tonight...\n",
      "11    six chanc win cash nmbr nmbr nmbr pound txt cs...\n",
      "12    urgent nmbr week free membership nmbr nmbr pri...\n",
      "13    search right word thank breather promi wont ta...\n",
      "14                                date sunday moneysymb\n",
      "15    xxxmobilemovieclub use credit click wap link n...\n",
      "16                                 oh k watch moneysymb\n",
      "17    eh u rememb nmbr spell name ye v naughti make ...\n",
      "18                  fine way u feel way gota bmoneysymb\n",
      "19    england v macedonia dont miss goal team news t...\n",
      "20                          seriou spell name moneysymb\n",
      "21              go tri nmbr month ha ha jokingmoneysymb\n",
      "22             ü pay first lar da stock comin moneysymb\n",
      "23    aft finish lunch go str lor ard nmbr smth lor ...\n",
      "24         ffffffffff alright way meet sooner moneysymb\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "all_word=[]\n",
    "for message in processed:\n",
    "    words=word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_word.append(w)\n",
    "all_word=nltk.FreqDist(all_word)            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 7281\n",
      "Most common words: [('moneysymb', 3169), ('nmbr', 2810), ('u', 1198), ('call', 663), ('go', 454), ('get', 452), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 300), ('ok', 281), ('free', 278), ('know', 269), ('love', 262), ('day', 260)]\n"
     ]
    }
   ],
   "source": [
    "print('Number of words: {}'.format(len(all_word)))\n",
    "print('Most common words: {}'.format(all_word.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features=list(all_word.keys())[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "jurong\n",
      "point\n",
      "crazi\n",
      "avail\n",
      "bugi\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "cine\n",
      "got\n",
      "amor\n",
      "wat\n",
      "moneysymb\n"
     ]
    }
   ],
   "source": [
    "#find feature function\n",
    "def find_features(message):\n",
    "    words=word_tokenize(message)\n",
    "    features={}\n",
    "    for word in word_features:\n",
    "        features[word]=(word in words)\n",
    "    return features\n",
    "\n",
    "#example\n",
    "features=find_features(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value==True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find features of all messages\n",
    "messages= list(zip(processed,y))\n",
    "#define a seed for reproductivity\n",
    "seed=1\n",
    "np.random.seed=seed\n",
    "np.random.shuffle(messages) \n",
    "\n",
    "#call find feature function for each messages\n",
    "featuresets = [(find_features(text),label) for (text,label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split faeture set to tarin and test data\n",
    "from sklearn import model_selection\n",
    "training,testing=model_selection.train_test_split(featuresets,test_size=0.40,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3343\n",
      "2229\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit learn classifier with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['K nearest neighbor','Decision Tree','Random Forest','Logistic Regression','SGD Classifier','Naive Bayes','SVM Linear']\n",
    "classifiers=[\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter=100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel='linear')\n",
    "]\n",
    "\n",
    "models = zip(names,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K nearest neighbor: Accuracy 92.23867205024675:\n",
      "Decision Tree: Accuracy 97.1736204576043:\n",
      "Random Forest: Accuracy 98.34006280843428:\n",
      "Logistic Regression: Accuracy 98.38492597577388:\n",
      "SGD Classifier: Accuracy 98.65410497981158:\n",
      "Naive Bayes: Accuracy 98.4297891431135:\n",
      "SVM Linear: Accuracy 98.56437864513235:\n"
     ]
    }
   ],
   "source": [
    "#wrap models into nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "for name,model in models:\n",
    "    nltk_model=SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy=nltk.classify.accuracy(nltk_model,testing)*100\n",
    "    print('{}: Accuracy {}:'.format(name,accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Method Accuracy 98.65410497981158:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "names=['K nearest neighbor','Decision Tree','Random Forest','Logistic Regression','SGD Classifier','Naive Bayes','SVM Linear']\n",
    "classifiers=[\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter=100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel='linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifiers))\n",
    "\n",
    "nltk_ensemble=SklearnClassifier(VotingClassifier(estimators=models,voting='hard',n_jobs=-1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy=nltk.classify.accuracy(nltk_ensemble,testing)*100\n",
    "print('Ensemble Method Accuracy {}:'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features,label=zip(*testing)\n",
    "prediction=nltk_ensemble.classify_many(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1925\n",
      "           1       1.00      0.90      0.95       304\n",
      "\n",
      "    accuracy                           0.99      2229\n",
      "   macro avg       0.99      0.95      0.97      2229\n",
      "weighted avg       0.99      0.99      0.99      2229\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>ham</th>\n",
       "      <td>1925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>30</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1925    0\n",
       "       spam        30  274"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(label,prediction))\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(label,prediction),\n",
    "     index = [['actual','actual'],['ham','spam']],\n",
    "     columns = [['predicted','predicted'],['ham','spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
